{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14837151,"sourceType":"datasetVersion","datasetId":9489293}],"dockerImageVersionId":31259,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-14T10:18:37.870840Z","iopub.execute_input":"2026-02-14T10:18:37.871201Z","iopub.status.idle":"2026-02-14T10:18:37.880501Z","shell.execute_reply.started":"2026-02-14T10:18:37.871172Z","shell.execute_reply":"2026-02-14T10:18:37.879198Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/datasets/aljowharahalshabaan/miniprojectweak3/day15_real_dataset_large.csv\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\npath=\"/kaggle/input/datasets/aljowharahalshabaan/miniprojectweak3/day15_real_dataset_large.csv\"\ndf_or=pd.read_csv(path)\nprint(df_or.head(),\"\\n\")\nprint(df_or.info(),\"\\n\")\nprint(df_or.describe(),\"\\n\")\nprint(df_or.nunique().sort_values(ascending=False).head(10),\"\\n\")\n\n\ncleaning_plan = {\n\"age\": {\"type\": \"float\", \"missing\": \"median_imp\", \"outliers\": \"cap_99\"},\n\"income\": {\"type\": \"float\", \"missing\": \"median_imp\", \"outliers\": \"log1p_cap_99\"},\n\"city\": {\"type\": \"category\", \"clean\": \"canonical_city\"},\n\"signup_time\": {\"type\": \"datetime\", \"tz\": \"UTC\"}}\n\ndef clean_data_project(df):\n    df1 = df.copy()\n# Types\n    df1[\"age\"] = pd.to_numeric(df1[\"age\"], errors=\"coerce\")\n    df1[\"income\"] = pd.to_numeric(df1[\"income\"], errors=\"coerce\")\n    df1[\"signup_time\"] = pd.to_datetime(df1[\"signup_time\"], errors=\"coerce\")\n    # Missing\n    df1=df1.dropna(subset=[\"income\"])\n    df1[\"age_missing\"] = df1[\"age\"].isna().astype(int)\n    df1[\"age\"] = df1[\"age\"].fillna(df1[\"age\"].median())\n    df1[\"income_missing\"] = df1[\"income\"].isna().astype(int)\n    df1[\"income\"] = df1[\"income\"].fillna(df1[\"income\"].median())\n    df1[\"city_missing\"]=df1[\"city\"].isna().astype(int)\n    df1[\"signup_missing\"]=df1[\"signup_time\"].isna().astype(int)\n    #duplicates\n    dups=df1.duplicated()\n    df1=df1.drop_duplicates(subset=[\"income\",\"city\",\"signup_time\"])\n    # Outliers\n    df1[\"income\"] = df1[\"income\"].clip(upper=df1[\"income\"].quantile(0.99))\n    df1[\"age\"]=np.log1p(df1[\"age\"])\n    # Strings and dates\n    df1[\"city\"] = df1[\"city\"].str.strip().str.lower()\n    canonical_map = {\"new york\": \"new york\", \"nyc\": \"new york\", \"ny\": \"new york\",\"san francisco\": \"san francisco\", \"sanfrancisco\": \"san francisco\"}\n    df1[\"city_token\"] = df1[\"city\"].str.replace(\" \", \"\", regex=False)\n    df1[\"city_canonical\"] = df1[\"city_token\"].map(canonical_map).fillna(df1[\"city\"])\n    custom_missing = [\"N/A\", \"NA\", \"not reported\", \"unknown\", \"?\"]\n    df1[\"city\"]=df1[\"city\"].replace(custom_missing,np.nan)\n    df1[\"signup_time\"] = df1[\"signup_time\"].dt.tz_localize(\"UTC\")\n    return df1\ndf_clean=clean_data_project(df_or)\nprint(\"===================================\\n\")\nprint(\"=============after cleaning:==================\")\nprint(df_clean.info())\nprint(df_clean[[\"age\", \"income\"]].describe())\nprint(df_clean[\"city\"].value_counts().head())\nprint(df_clean[\"signup_time\"].dt.tz)\nprint(df_clean.isna().sum())\ndf_clean.to_csv(\"clean_data.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T10:28:21.705707Z","iopub.execute_input":"2026-02-14T10:28:21.706479Z","iopub.status.idle":"2026-02-14T10:28:21.772124Z","shell.execute_reply.started":"2026-02-14T10:28:21.706443Z","shell.execute_reply":"2026-02-14T10:28:21.771135Z"}},"outputs":[{"name":"stdout","text":"       age    income     city signup_time\n0       30   55000.0       NY  2024-01-01\n1      NaN   70000.0       SF  2024-01-05\n2       45       NaN       LA  not a date\n3  unknown  120000.0       NY  2024/02/01\n4       28   65000.0  Chicago  2024-01-15 \n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 97 entries, 0 to 96\nData columns (total 4 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   age          78 non-null     object \n 1   income       77 non-null     float64\n 2   city         96 non-null     object \n 3   signup_time  97 non-null     object \ndtypes: float64(1), object(3)\nmemory usage: 3.2+ KB\nNone \n\n              income\ncount      77.000000\nmean    77077.922078\nstd     18780.425303\nmin     45000.000000\n25%     62000.000000\n50%     75000.000000\n75%     91000.000000\nmax    120000.000000 \n\nsignup_time    95\nincome         62\ncity           59\nage            30\ndtype: int64 \n\n===================================\n\n=============after cleaning:==================\n<class 'pandas.core.frame.DataFrame'>\nIndex: 77 entries, 0 to 96\nData columns (total 10 columns):\n #   Column          Non-Null Count  Dtype              \n---  ------          --------------  -----              \n 0   age             73 non-null     float64            \n 1   income          77 non-null     float64            \n 2   city            76 non-null     object             \n 3   signup_time     34 non-null     datetime64[ns, UTC]\n 4   age_missing     77 non-null     int64              \n 5   income_missing  77 non-null     int64              \n 6   city_missing    77 non-null     int64              \n 7   signup_missing  77 non-null     int64              \n 8   city_token      76 non-null     object             \n 9   city_canonical  76 non-null     object             \ndtypes: datetime64[ns, UTC](1), float64(2), int64(4), object(3)\nmemory usage: 6.6+ KB\nNone\n             age         income\ncount  73.000000      77.000000\nmean    3.564389   77028.571429\nstd     0.144398   18670.824814\nmin     3.258097   45000.000000\n25%     3.526361   62000.000000\n50%     3.555348   75000.000000\n75%     3.637586   91000.000000\nmax     3.912023  116200.000000\ncity\nny         4\nsf         3\naustin     3\nchicago    2\nseattle    2\nName: count, dtype: int64\nUTC\nage                4\nincome             0\ncity               1\nsignup_time       43\nage_missing        0\nincome_missing     0\ncity_missing       0\nsignup_missing     0\ncity_token         1\ncity_canonical     1\ndtype: int64\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n  result = getattr(ufunc, method)(*inputs, **kwargs)\n","output_type":"stream"}],"execution_count":27}]}